import json
import os
from typing import Dict, List, Optional, Any, TYPE_CHECKING
from openai import AsyncOpenAI
from json_repair import repair_json
from datetime import datetime
from base_agent import BaseAgent, ExecutionStep, PlanningResult, StepStatus, AgentState
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, TaskID, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.panel import Panel
from rich.tree import Tree
from rich.live import Live
import time
from prompt import QUERY_ANALYSIS_PROMPT, PLAN_GENERATION_PROMPT, THINKING_PROMPT, REFLECTION_PROMPT, FINAL_RESPONSE_PROMPT

# å¸¸é‡å®šä¹‰
DEFAULT_ANALYSIS_RESULT = {
    "intent": "",
    "query_rewrite": "",
    "keywords": [],
    "entities": [],
    "constraints": {
        "time_range": "",
        "language": "",
        "sources": [],
        "file_types": [],
        "limit": 20
    },
    "required_tool_types": [],
    "tool_candidates": [],
    "strategies": ["ç›´æ¥æ‰§è¡Œ"],
    "challenges": [],
    "estimated_steps": 3
}

DEFAULT_PLANNING_RESULT = {
    "steps": [],
    "reasoning": "è®¡åˆ’ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥",
    "confidence": 0.3,
    "estimated_time_minutes": 5,
    "fallbacks": ["ä½¿ç”¨å¤‡ç”¨ç­–ç•¥"],
    "stopping_criteria": "è·å¾—åŸºæœ¬ç»“æœ"
}

# Use TYPE_CHECKING to avoid circular import
if TYPE_CHECKING:
    from client import MCPClient

class MCPAgent(BaseAgent):
    """åŸºäºMCPçš„æ™ºèƒ½Agentå®ç°"""
    
    def __init__(self, name: str, config: Dict[str, Any], mcp_client: 'MCPClient'):
        super().__init__(name, config)
        self.mcp_client = mcp_client
        self.openai = AsyncOpenAI(
            api_key=os.getenv("ERNIE_APIKEY"), 
            base_url=os.getenv("ERNIE_BASE_URL")
        )
        self.console = Console()
        self.progress = None
        self.current_task_id = None
    
    async def _call_openai(self, prompt: str, model_type: str = "thinking", temperature: float = 0.3, max_tokens: int = 4096) -> str:
        """é€šç”¨çš„OpenAIè°ƒç”¨æ–¹æ³•"""
        model_map = {
            "thinking": os.getenv("ERNIE_THINKING_MODEL"),
            "chat": os.getenv("ERNIE_CHAT_MODEL")
        }
        
        model = model_map.get(model_type, os.getenv("ERNIE_THINKING_MODEL"))
        
        try:
            completion = await self.openai.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens
            )
            return completion.choices[0].message.content
        except Exception as e:
            raise Exception(f"OpenAIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def process_query(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„ä¸»è¦å…¥å£ç‚¹ï¼Œå¸¦è¿›åº¦æ˜¾ç¤º"""
        try:
            self.state = AgentState.PLANNING
            
            # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
            self.console.print(Panel.fit(
                f"ğŸ¤– [bold blue]æ™ºèƒ½Agentå¼€å§‹å¤„ç†æŸ¥è¯¢[/bold blue]\n\næŸ¥è¯¢: {query}",
                title="Agentå¯åŠ¨",
                border_style="blue"
            ))
            
            # 1. æ€è€ƒå’Œè§„åˆ’é˜¶æ®µ
            self.console.print("\n[bold magenta]ğŸ“‹ é˜¶æ®µ1: æ™ºèƒ½è§„åˆ’[/bold magenta]")
            planning_result = await self._plan_execution_with_display(query, context)
            if not planning_result:
                return "æ— æ³•ä¸ºæ­¤æŸ¥è¯¢åˆ¶å®šæ‰§è¡Œè®¡åˆ’"
            
            self.current_plan = planning_result
            self.current_step_index = 0
            
            # æ˜¾ç¤ºè§„åˆ’ç»“æœ
            self._display_plan(planning_result)
            
            # 2. æ‰§è¡Œé˜¶æ®µ
            self.state = AgentState.EXECUTING
            self.console.print("\n[bold green]âš¡ é˜¶æ®µ2: æ‰§è¡Œè®¡åˆ’[/bold green]")
            execution_results = await self._execute_plan_with_progress()
            
            # 3. æœ€ç»ˆåæ€å’Œæ€»ç»“
            self.state = AgentState.REFLECTING
            self.console.print("\n[bold yellow]ğŸ¤” é˜¶æ®µ3: åæ€æ€»ç»“[/bold yellow]")
            final_response = await self._generate_final_response(query, execution_results)
            
            self.state = AgentState.COMPLETED
            
            # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
            self.console.print(Panel.fit(
                f"âœ… [bold green]ä»»åŠ¡æ‰§è¡Œå®Œæˆ[/bold green]\n\nå…±æ‰§è¡Œ {len(execution_results)} ä¸ªæ­¥éª¤",
                title="æ‰§è¡Œå®Œæˆ",
                border_style="green"
            ))
            
            return final_response
            
        except Exception as e:
            self.state = AgentState.ERROR
            self.console.print(Panel.fit(
                f"âŒ [bold red]æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯[/bold red]\n\né”™è¯¯: {str(e)}",
                title="æ‰§è¡Œå¤±è´¥",
                border_style="red"
            ))
            return f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    async def _plan_execution_with_display(self, query: str, context: Optional[Dict[str, Any]] = None) -> Optional[PlanningResult]:
        """å¸¦æ˜¾ç¤ºçš„è§„åˆ’æ‰§è¡Œæ­¥éª¤"""
        with self.console.status("[bold blue]æ­£åœ¨åˆ†ææŸ¥è¯¢å’Œæ”¶é›†å·¥å…·ä¿¡æ¯...") as status:
            # æ”¶é›†å¯ç”¨å·¥å…·ä¿¡æ¯
            available_tools = await self._get_available_tools()
            status.update("[bold blue]æ­£åœ¨æ·±åº¦åˆ†æç”¨æˆ·æ„å›¾...")
            
            # åˆ†ææŸ¥è¯¢å’Œä¸Šä¸‹æ–‡
            analysis = await self._analyze_query(query, context, available_tools)
            status.update("[bold blue]æ­£åœ¨åˆ¶å®šæœ€ä¼˜æ‰§è¡Œè®¡åˆ’...")
            
            # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            planning_result = await self._generate_plan(query, analysis, available_tools)
        
        # è®°å½•è§„åˆ’è¿‡ç¨‹
        self.memory.conversation_history.append({
            "type": "planning",
            "query": query,
            "context": context,
            "planning_result": planning_result,
            "timestamp": datetime.now()
        })
        
        return planning_result
    
    def _display_plan(self, planning_result: PlanningResult):
        """æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’"""
        # åˆ›å»ºè®¡åˆ’æ ‘çŠ¶å›¾
        tree = Tree("ğŸ“‹ [bold blue]æ‰§è¡Œè®¡åˆ’[/bold blue]")
        
        # æ·»åŠ è§„åˆ’æ¨ç†
        reasoning_branch = tree.add("ğŸ§  [yellow]è§„åˆ’æ¨ç†[/yellow]")
        reasoning_branch.add(planning_result.reasoning)
        
        # æ·»åŠ ç½®ä¿¡åº¦å’Œé¢„ä¼°æ—¶é—´
        confidence_branch = tree.add(f"ğŸ“Š [cyan]ç½®ä¿¡åº¦: {planning_result.confidence:.1%}[/cyan]")
        if planning_result.estimated_time_minutes:
            time_branch = tree.add(f"â±ï¸ [cyan]é¢„ä¼°æ—¶é—´: {planning_result.estimated_time_minutes}åˆ†é’Ÿ[/cyan]")
        
        # æ·»åŠ æ‰§è¡Œæ­¥éª¤
        steps_branch = tree.add("ğŸ“ [green]æ‰§è¡Œæ­¥éª¤[/green]")
        for i, step in enumerate(planning_result.steps, 1):
            # ç¡®ä¿ description æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if isinstance(step.description, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå¯è¯»çš„å­—ç¬¦ä¸²
                step_description = f"{step.description.get('description', 'æœªçŸ¥æ­¥éª¤')}"
            elif isinstance(step.description, str):
                step_description = step.description
            else:
                # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                step_description = str(step.description)
            
            step_text = f"æ­¥éª¤{i}: {step_description}"
            if step.step_type:
                step_text += f" [dim]({step.step_type})[/dim]"
            if step.tool_name:
                step_text += f" [dim](å·¥å…·: {step.tool_name})[/dim]"
            if step.server_name:
                step_text += f" [dim](æœåŠ¡å™¨: {step.server_name})[/dim]"
            steps_branch.add(step_text)
        
        # æ·»åŠ å›é€€ç­–ç•¥
        if planning_result.fallbacks:
            fallback_branch = tree.add("ğŸ”„ [orange3]å›é€€ç­–ç•¥[/orange3]")
            for fallback in planning_result.fallbacks:
                fallback_branch.add(fallback)
        
        # æ·»åŠ åœæ­¢æ¡ä»¶
        if planning_result.stopping_criteria:
            criteria_branch = tree.add("ğŸ¯ [magenta]åœæ­¢æ¡ä»¶[/magenta]")
            criteria_branch.add(planning_result.stopping_criteria)
        
        self.console.print(tree)
        self.console.print()
    
    async def _execute_plan_with_progress(self) -> List[ExecutionStep]:
        """å¸¦è¿›åº¦æ¡çš„æ‰§è¡Œè®¡åˆ’"""
        execution_results = []
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            
            # åˆ›å»ºæ€»ä½“è¿›åº¦ä»»åŠ¡
            total_task = progress.add_task(
                "[cyan]æ€»ä½“è¿›åº¦", 
                total=len(self.current_plan.steps)
            )
            
            while self.current_step_index < len(self.current_plan.steps):
                step = self.current_plan.steps[self.current_step_index]
                
                # åˆ›å»ºå½“å‰æ­¥éª¤çš„è¿›åº¦ä»»åŠ¡
                step_task = progress.add_task(
                    f"[green]æ­¥éª¤{self.current_step_index + 1}: {step.description[:50]}...",
                    total=100
                )
                
                # æ‰§è¡Œå‰æ€è€ƒ
                progress.update(step_task, advance=20, description=f"[yellow]æ€è€ƒä¸­: {step.description[:40]}...")
                await self._think_before_execution(step)
                
                # æ‰§è¡Œæ­¥éª¤
                progress.update(step_task, advance=30, description=f"[blue]æ‰§è¡Œä¸­: {step.description[:40]}...")
                step.status = StepStatus.EXECUTING
                start_time = time.time()
                
                try:
                    result = await self._execute_step(step)
                    step.result = result
                    # ç¡®ä¿çŠ¶æ€æ›´æ–°
                    if result and result.strip():
                        step.status = StepStatus.COMPLETED
                    else:
                        step.status = StepStatus.FAILED
                        step.error = "æ­¥éª¤æ‰§è¡Œå®Œæˆä½†æœªè¿”å›æœ‰æ•ˆç»“æœ"
                    step.execution_time = time.time() - start_time
                    progress.update(step_task, advance=30, description=f"[green]âœ… å®Œæˆ: {step.description[:40]}...")
                    
                except Exception as e:
                    step.error = str(e)
                    step.status = StepStatus.FAILED
                    step.execution_time = time.time() - start_time
                    progress.update(step_task, advance=30, description=f"[red]âŒ å¤±è´¥: {step.description[:40]}...")
                
                # æ‰§è¡Œååæ€
                progress.update(step_task, advance=20, description=f"[magenta]åæ€ä¸­: {step.description[:40]}...")
                await self._reflect_on_step(step)
                
                # å®Œæˆå½“å‰æ­¥éª¤
                progress.update(step_task, completed=100)
                progress.remove_task(step_task)
                
                execution_results.append(step)
                self.memory.execution_history.append(step)
                
                # æ›´æ–°æ€»ä½“è¿›åº¦
                progress.update(total_task, advance=1)
                
                # æ˜¾ç¤ºæ­¥éª¤ç»“æœæ‘˜è¦
                self._display_step_result(step, self.current_step_index + 1)
                
                # æ ¹æ®åæ€ç»“æœå†³å®šæ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’
                if await self._should_replan(step, execution_results):
                    self.console.print("[yellow]âš ï¸  æ£€æµ‹åˆ°éœ€è¦é‡æ–°è§„åˆ’ï¼Œæ­£åœ¨è°ƒæ•´ç­–ç•¥...[/yellow]")
                    new_plan = await self._replan(execution_results)
                    if new_plan:
                        self.current_plan = new_plan
                        self.current_step_index = 0
                        # é‡æ–°è®¾ç½®è¿›åº¦æ¡
                        progress.update(total_task, completed=0, total=len(new_plan.steps))
                        continue
                
                self.current_step_index += 1
        
        return execution_results
    
    def _display_step_result(self, step: ExecutionStep, step_number: int):
        """æ˜¾ç¤ºæ­¥éª¤æ‰§è¡Œç»“æœ"""
        if step.status == StepStatus.COMPLETED:
            status_icon = "âœ…"
            status_color = "green"
            status_text = "æˆåŠŸ"
        elif step.status == StepStatus.FAILED:
            status_icon = "âŒ"
            status_color = "red"
            status_text = "å¤±è´¥"
        else:
            status_icon = "â³"
            status_color = "yellow"
            status_text = "è¿›è¡Œä¸­"
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        table = Table(show_header=False, box=None, padding=(0, 1))
        table.add_column("å±æ€§", style="bold")
        table.add_column("å€¼")
        
        table.add_row("çŠ¶æ€", f"[{status_color}]{status_icon} {status_text}[/{status_color}]")
        table.add_row("æ‰§è¡Œæ—¶é—´", f"{step.execution_time:.2f}ç§’" if step.execution_time else "æœªçŸ¥")
        
        if step.result:
            result_preview = step.result[:100] + "..." if len(step.result) > 100 else step.result
            table.add_row("ç»“æœé¢„è§ˆ", result_preview)
        
        if step.error:
            table.add_row("é”™è¯¯ä¿¡æ¯", f"[red]{step.error}[/red]")
        
        if step.confidence_score:
            confidence_color = "green" if step.confidence_score > 0.7 else "yellow" if step.confidence_score > 0.4 else "red"
            table.add_row("ç½®ä¿¡åº¦", f"[{confidence_color}]{step.confidence_score:.1%}[/{confidence_color}]")
        
        panel = Panel(
            table,
            title=f"æ­¥éª¤ {step_number} ç»“æœ",
            border_style=status_color
        )
        
        self.console.print(panel)
        self.console.print()
    
    async def _get_available_tools(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰MCPæœåŠ¡å™¨çš„å¯ç”¨å·¥å…·"""
        all_tools = []
        
        for server_name, session in self.mcp_client.sessions.items():
            try:
                response = await session.list_tools()
                server_tools = [{
                    "server": server_name,
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                } for tool in response.tools]
                all_tools.extend(server_tools)
            except Exception as e:
                print(f"è·å–æœåŠ¡å™¨ {server_name} å·¥å…·å¤±è´¥: {str(e)}")
        
        return all_tools
    
    async def _analyze_query(self, query: str, context: Optional[Dict[str, Any]], available_tools: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        analysis_prompt = QUERY_ANALYSIS_PROMPT.format(
            query=query,
            context=json.dumps(context or {}, ensure_ascii=False, indent=2),
            available_tools=json.dumps([{"name": t["name"], "description": t["description"]} for t in available_tools], ensure_ascii=False, indent=2)
        )
        
        try:
            response_text = await self._call_openai(analysis_prompt, "thinking", 0.3)
            response_text = repair_json(response_text)
            return json.loads(response_text)
            
        except Exception as e:
            print(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}")
            result = DEFAULT_ANALYSIS_RESULT.copy()
            result["intent"] = query
            return result
    
    async def _generate_plan(self, query: str, analysis: Dict[str, Any], available_tools: List[Dict[str, Any]]) -> PlanningResult:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        planning_prompt = PLAN_GENERATION_PROMPT.format(
            query=query,
            analysis=json.dumps(analysis, ensure_ascii=False, indent=2),
            available_tools=json.dumps(available_tools, ensure_ascii=False, indent=2)
        )
        
        try:
            response_text = await self._call_openai(planning_prompt, "thinking", 0.4)
            response_text = repair_json(response_text)
            plan_data = json.loads(response_text)
            
            # è½¬æ¢ä¸ºExecutionStepå¯¹è±¡
            steps = []
            for step_data in plan_data.get("steps", []):
                # ç¡®ä¿ description æ˜¯å­—ç¬¦ä¸²ç±»å‹
                description = step_data.get("description", "")
                if isinstance(description, dict):
                    description = description.get("description", str(description))
                elif not isinstance(description, str):
                    description = str(description)
                
                step = ExecutionStep(
                    step_id=step_data["step_id"],
                    description=description,  # ä½¿ç”¨å¤„ç†åçš„ description
                    tool_name=step_data.get("tool_name"),
                    server_name=step_data.get("server_name"),
                    parameters=step_data.get("parameters", {}),
                    step_type=step_data.get("type")  # æ–°å¢å­—æ®µ
                )
                steps.append(step)
            
            return PlanningResult(
                steps=steps,
                reasoning=plan_data.get("reasoning", ""),
                confidence=plan_data.get("confidence", 0.5),
                estimated_time=plan_data.get("estimated_time"),
                estimated_time_minutes=plan_data.get("estimated_time_minutes"),  # æ–°å¢
                fallbacks=plan_data.get("fallbacks", []),  # æ–°å¢
                stopping_criteria=plan_data.get("stopping_criteria")  # æ–°å¢
            )
            
        except Exception as e:
            print(f"è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤è®¡åˆ’
            return PlanningResult(
                steps=DEFAULT_PLANNING_RESULT["steps"],
                reasoning=DEFAULT_PLANNING_RESULT["reasoning"],
                confidence=DEFAULT_PLANNING_RESULT["confidence"],
                estimated_time_minutes=DEFAULT_PLANNING_RESULT["estimated_time_minutes"],
                fallbacks=DEFAULT_PLANNING_RESULT["fallbacks"],
                stopping_criteria=DEFAULT_PLANNING_RESULT["stopping_criteria"]
            )
    
    async def _execute_step(self, step: ExecutionStep) -> str:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        if not step.tool_name or not step.server_name:
            raise Exception("æ­¥éª¤ç¼ºå°‘å¿…è¦çš„å·¥å…·æˆ–æœåŠ¡å™¨ä¿¡æ¯")
        
        if step.server_name not in self.mcp_client.sessions:
            raise Exception(f"æœåŠ¡å™¨ {step.server_name} ä¸å¯ç”¨")
        
        session = self.mcp_client.sessions[step.server_name]
        
        # å‡†å¤‡å‚æ•°ï¼ˆå¤„ç†å ä½ç¬¦ï¼‰
        prepared_params = self._prepare_step_params(step)
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        result = await session.call_tool(step.tool_name, prepared_params)
        
        if result.content and len(result.content) > 0:
            return result.content[0].text
        else:
            return "æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›å†…å®¹"
    
    def _prepare_step_params(self, step: ExecutionStep) -> Dict[str, Any]:
        """å‡†å¤‡æ­¥éª¤å‚æ•°ï¼Œå¤„ç†å ä½ç¬¦"""
        params = step.parameters.copy()
        
        # è·å–ä¹‹å‰çš„æˆåŠŸç»“æœ
        previous_results = [s for s in self.memory.execution_history if s.status == StepStatus.COMPLETED]
        
        if not previous_results:
            return params
        
        # æ›¿æ¢å ä½ç¬¦
        for key, value in params.items():
            if isinstance(value, str):
                if "{{previous_result}}" in value:
                    latest_result = previous_results[-1].result or ""
                    params[key] = value.replace("{{previous_result}}", latest_result)
                
                # å¤„ç†ç‰¹å®šæ­¥éª¤ç»“æœå¼•ç”¨
                import re
                step_pattern = r'\{\{step_([^}]+)_result\}\}'
                matches = re.findall(step_pattern, value)
                for step_id in matches:
                    step_result = next((s.result for s in previous_results if s.step_id == step_id), "")
                    placeholder = f"{{{{step_{step_id}_result}}}}"
                    params[key] = value.replace(placeholder, step_result or "")
        
        return params
    
    async def _generate_thinking(self, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€è€ƒå†…å®¹"""
        thinking_prompt = THINKING_PROMPT.format(
            context=json.dumps(context, ensure_ascii=False, indent=2, default=str)
        )
        
        try:
            return await self._call_openai(thinking_prompt, "thinking", 0.6)
            
        except Exception as e:
            return f"æ€è€ƒè¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    async def _generate_reflection(self, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆåæ€å†…å®¹"""
        reflection_prompt = REFLECTION_PROMPT.format(
            context=json.dumps(context, ensure_ascii=False, indent=2, default=str)
        )
        
        try:
            return await self._call_openai(reflection_prompt, "thinking", 0.6)
            
        except Exception as e:
            return f"åæ€è¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    async def _generate_final_response(self, query: str, execution_results: List[ExecutionStep]) -> str:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        # æå–æˆåŠŸæ‰§è¡Œçš„ç»“æœå†…å®¹ - ä¿®å¤çŠ¶æ€æ£€æŸ¥
        successful_results = []
        for step in execution_results:
            # ä¿®æ”¹æ¡ä»¶ï¼šåŒ…å«æœ‰ç»“æœçš„æ­¥éª¤ï¼Œä¸ä»…ä»…æ˜¯COMPLETEDçŠ¶æ€
            if step.result and step.result.strip():
                # é¢å¤–æ£€æŸ¥ï¼šæ’é™¤æ˜æ˜¾çš„é”™è¯¯ç»“æœ
                if not step.result.startswith("æŠ±æ­‰") and not step.result.startswith("æ— æ³•"):
                    successful_results.append(step.result)
            # å¦‚æœæ²¡æœ‰æˆåŠŸç»“æœï¼Œä½†æ­¥éª¤çŠ¶æ€æ˜¯COMPLETEDï¼Œä¹Ÿå°è¯•åŒ…å«
            elif step.status == StepStatus.COMPLETED and step.result:
                successful_results.append(step.result)
        
        # åˆå¹¶æ‰€æœ‰æˆåŠŸçš„ç»“æœ
        combined_results = "\n\n".join(successful_results)
        
        final_prompt = FINAL_RESPONSE_PROMPT.format(
            query=query,
            combined_results=combined_results
        )
        
        try:
            return await self._call_openai(final_prompt, "chat", 0.6)
            
        except Exception as e:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è¿”å›åˆå¹¶çš„ç»“æœ
            if combined_results:
                return combined_results
            else:
                return f"æŠ±æ­‰ï¼Œæ— æ³•è·å–åˆ°å…³äº'{query}'çš„ç›¸å…³ä¿¡æ¯ã€‚"